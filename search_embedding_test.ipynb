{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   # Generates embedding for a text\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    " \n",
    "# What does this do?\n",
    "def get_embeddings(\n",
    "    list_of_text: list[str], model=\"text-embedding-3-small\", **kwargs) -> list[list[float]]:\n",
    "    assert len(list_of_text) <= 2048, \"The batch size should not be larger than 2048.\"\n",
    "    list_of_text = [text.replace(\"\\n\", \" \") for text in list_of_text]\n",
    "    data = client.embeddings.create(input=list_of_text, model=model, **kwargs).data\n",
    "    return [d.embedding for d in data]\n",
    "\n",
    "def create_embeddings_data(file,embedded_name, model=\"text-embedding-3-small\"):\n",
    "    df = pd.read_csv(file)\n",
    "    df['embeddings'] = get_embeddings(df['text'], model=model)\n",
    "    df.to_csv(embedded_name, index=False)\n",
    "        \n",
    "def load_embeddings_data(file):\n",
    "    df = pd.read_csv(file)\n",
    "    df['embeddings'] = df['embeddings'].apply(eval).apply(np.array)\n",
    "    return df\n",
    "\n",
    "def get_most_similar(text, df, n=3):\n",
    "    search_embedded = get_embedding(text)\n",
    "    df['similarities'] = df['embeddings'].apply(lambda x : cosine_similarity(x,search_embedded))\n",
    "    df = df.sort_values(\"similarities\", ascending=False)\n",
    "    df = df.reset_index(drop=True)\n",
    "    for i in range(n):\n",
    "        print(f'Suggestion {i}: {df[\"text\"][i]}')\n",
    "\n",
    "def get_most_similar_unique(text, df, n=1):\n",
    "    #  Split the input text into unique words\n",
    "    words = set(text.split())\n",
    "    # Iterate over each word and get the most similar embeddings\n",
    "    for word in words:\n",
    "        get_most_similar(word, df, n)\n",
    "        \n",
    "def jaccard_similarity(embedding1, embedding2):\n",
    "    set1 = set(embedding1)\n",
    "    set2 = set(embedding2)\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "answer = input(\"Do you want to create embeddings for the text in fed-speech.csv? (y/any key): \")\n",
    "if answer == \"y\":\n",
    "    create_embeddings_data(\"fed-speech.csv\") # creates embeddings for the text in fed-speech.csv and saves it to fed-speech-embeddings.csv\n",
    "    df = load_embeddings_data('fed-speech-embeddings.csv') # loads the embeddings from fed-speech-embeddings.csv\n",
    "    search = \"PCE fomc august prices\" # search query\n",
    "    get_most_similar(search,df) # get the most similar text to the search query\n",
    "    get_most_similar_unique(search,df) # get the most similar text to the search query for each unique word\n",
    "    get_most_similar(\"the federal open market comittee\",df,n=3) # less specific search query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split PDF by pages and split by contract number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_pdf_by_page_to_csv(pdf_file):\n",
    "    # Each page in the pdf is stored in a separate row in the csv file\n",
    "    pdf = PyPDF2.PdfReader(pdf_file)\n",
    "    chunks = []\n",
    "    chunk = \"\"\n",
    "    for i in range(len(pdf.pages)):\n",
    "        page = pdf.pages[i]\n",
    "        text = page.extract_text()\n",
    "        for line in text.split(\"\\n\"):\n",
    "            if line == \"\":\n",
    "                chunks.append(chunk)\n",
    "                chunk = \"\"\n",
    "            else:\n",
    "                chunk += line + \" \"\n",
    "    df = pd.DataFrame(chunks, columns=[\"text\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "def insert_newline_before_contract_number(text,pattern):\n",
    "    # Function to insert a newline before the contract number\n",
    "    return re.sub(pattern, r'\\n\\1', text)\n",
    "\n",
    "def chunk_by_contract_number(pdf_file, csv_file):\n",
    "    df = split_pdf_by_page_to_csv(pdf_file)\n",
    "    # Define the pattern for contract numbers (e.g., X., X.X., X.XX., XX.XX.)\n",
    "    pattern = r' (\\d{1,2}(\\.\\d{1,2})?\\.) '\n",
    "    \n",
    "    # Apply the function to the sentences and concatenate all rows into one string\n",
    "    all_text = '\\n'.join(df['text'].apply(lambda x : insert_newline_before_contract_number(x,pattern)))\n",
    "\n",
    "    # Split the concatenated text into separate rows based on the newline\n",
    "    split_sentences = [line for line in all_text.split('\\n') if line.strip()]\n",
    "\n",
    "    # Create a new DataFrame with the split sentences\n",
    "    new_df = pd.DataFrame(split_sentences, columns=['text'])\n",
    "\n",
    "    # Save the new DataFrame to a CSV file\n",
    "    new_df.to_csv('NS-test-split.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9713423673818518\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "str1 = \"The fox jumped over the cat\"\n",
    "str2 = \"The cat jumped over the fox\"\n",
    "\n",
    "emb1 = get_embedding(str1)\n",
    "emb2 = get_embedding(str2)\n",
    "\n",
    "print(cosine_similarity(emb1, emb2))\n",
    "print(jaccard_similarity(str1, str2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_embeddings_data(\"NS-test-split.csv\", \"NS-test-split-embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_embeddings_data(\"NS-test-split-embeddings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref. CCB krav: \"OBI-CON-036 Bygg F 1 etasje - merarbeid lime plater\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = \"Iht. punkt 3.18 mener vi at merkostnad for tilpasning til nevnte forhold ovenfor berettiger tilleggskostnadene.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestion 0: 3.30.  Prising av endringer   Alle priser i endringsmeldinger skal gjenspeile prisnivå på poster i postoppsettet.     Dette gjelder også for R&D  der 5% tillegges som fast sats.   Dersom det er spesielle forhold, f.eks. inntransport etter byggheis er demontert, er UE  berettiget til ytterlig ere kompensasjon for dette .    \n",
      "Suggestion 1: 3.31. Fordelingskostnader   \n",
      "Suggestion 2: 3.18.  Hulltaking i himling :  OBI har t ilbudt h ulltagning og kantforsegling himlinger kr 40, - pr m² .     Prisen inkluderer alle tilpasninger i himling . Blant annet, men ikke begrenset til:   hulltaking, tilpasning grid for lamper, tilpasning søyler, tilpasning til vegger,  kantforsegling av plater som kappes for både hull og tilpasninger. Prisen gjelde r for alle  typer himlinger.     Opplimt e akustisk plater (post 12 -13-14-15) omfattes ikke av d ette punkt. Plater  monteres etter teknisk inkl. i enhetspriser. Nødvendig tilpasning av plater som følge av  krasj med teknisk medfører tillegg. Omfang av dette avklar es før oppst art i soner.     Garasjehimling   OBI monterer garasjehimling etter teknisk. Avtalt  pris for dette kr 40 per m2 (likt som  for hulltaking og tilpasninger gener elt i himling) og kr 50 i til legg til dette for montering  etter tekniske fag. Totalt kr 90 per m2 tille gges tilbudte enhetspriser  i avtaledokument  og prisoppsett .     Situasjonen er slik for bygg D -G. Partene ser på sammen med tekni ske om situasjonen  kan endres til bygg A -C. Dersom OBI kan montere bæresystem før tekniske fag borer  \n"
     ]
    }
   ],
   "source": [
    "get_most_similar(search,df,n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestion 0: 3.29.   Rigg og drift   Rigg og drift  (R&D) , post 1 i tilbud for systeminnredning og post 1 i tilbud for himling.     R&D honoreres med 5% av etter faktisk utførte mengder.       3.30.   Prising av endringer   Alle priser i endringsmeldinger skal gjenspeile prisnivå på poster i postoppsettet.     Dette gjelder også for R&D  der 5% tillegges som fast sats.   Dersom det er spesielle forhold, f.eks. inntransport etter byggheis er demontert, er UE  berettiget til ytterlig ere kompensasjon for dette .     3.31.\n"
     ]
    }
   ],
   "source": [
    "get_most_similar(\"3.3.\",df,n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create meaningful chunks. Semantic text splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_text_splitter import TextSplitter\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "with open(\"NS-test.csv\", \"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "max_tokens = 200\n",
    "tokenizer = Tokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "splitter = TextSplitter.from_huggingface_tokenizer(tokenizer, max_tokens)\n",
    "chunks = splitter.chunks(content)\n",
    "# Create a DataFrame from the chunks\n",
    "df = pd.DataFrame({'text': chunks})\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('NS-chunk.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
